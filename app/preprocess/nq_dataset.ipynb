{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5508d473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'train_0', 'question': 'total number of death row inmates in the us?', 'golden_answers': array(['2,718'], dtype=object), 'data_source': 'nq', 'prompt': array([{'content': 'Answer the given question. You must conduct reasoning inside <think> and </think> first every time you get new information. After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. You can search as many times as your want. If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: total number of death row inmates in the us?\\n', 'role': 'user'}],\n",
      "      dtype=object), 'ability': 'fact-reasoning', 'reward_model': {'ground_truth': {'target': array(['2,718'], dtype=object)}, 'style': 'rule'}, 'extra_info': {'index': 0, 'split': 'train'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "data_dir = Path('/data/comm/RUC-NLPIR/FlashRAG_datasets/nq')\n",
    "train_file = data_dir / 'train.parquet'\n",
    "test_file = data_dir / 'test.parquet'\n",
    "\n",
    "def load_data(file_path):\n",
    "    if file_path.suffix == '.jsonl':\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "    elif file_path.suffix == '.parquet':\n",
    "        import pyarrow.parquet as pq\n",
    "        table = pq.read_table(file_path)\n",
    "        data = table.to_pandas().to_dict(orient='records')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_path.suffix}\")\n",
    "    return data\n",
    "\n",
    "data = load_data(train_file)\n",
    "print(data[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searchr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
